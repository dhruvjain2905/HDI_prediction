# -*- coding: utf-8 -*-
"""5Epoch_MultiModal_HDIDataCNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xhyY7nMRthmWHDvbSm9TKkuiiIK4UuPp
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
from PIL import Image
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from keras import models, layers
import pandas as pd
from sklearn.model_selection import train_test_split

world_data = pd.DataFrame()
for i in ["A1", "B1", "C1", "D1", "D2", "C2", "D2"]:

#could use more areas, but just focusing on a1 part of world for now
 #(Western US + Mexico + Carribbean)

  hdi_data = pd.read_csv("/content/drive/MyDrive/blackmarblecsv/"+i+"df.csv")
  hdi_data = hdi_data.drop(columns = ["Unnamed: 0", "pixel_values"])
  new_data = np.load("/content/drive/MyDrive/blackmarblenpy/"+i.lower()+".npy")

    # Load the large image
  Image.MAX_IMAGE_PIXELS = None
  image = Image.open("/content/drive/MyDrive/blackmarbleimages/BlackMarble_2016_"+i+".jpeg")

    # Define the desired size of the smaller pieces
  tile_width = 200
  tile_height = 200
  image_width = 86400
  image_height = 43200
    # Calculate the number of rows and columns needed to divide the image into tiles
  num_tiles_horizontal = image.width // tile_width
  num_tiles_vertical = image.height // tile_height

    # Create an empty DataFrame to store the pixel values
  image_data = []

    # Iterate over each tile and save them as separate images
  for i in range(num_tiles_vertical):
      for j in range(num_tiles_horizontal):
          left = j * tile_width
          upper = i * tile_height
          right = left + tile_width
          lower = upper + tile_height

          population = new_data[i, j]
          tile = image.crop((left, upper, right, lower))
          tile_array = np.array(tile)

          if population > 5000:
            image_data.append(tile_array)


  hdi_data["pixel_values"] = image_data

  world_data = world_data.append(hdi_data)

random_images = world_data.sample(n=10)  # Adjust the number as needed and set random_state for reproducibility
indexes = random_images.index
# Display the random images using matplotlib




for i in random_images.index:
    image_array = random_images.loc[i, 'pixel_values'] # Get the pixel values of the image
    #image = Image.fromarray(np.array(image_array))  # Create a PIL Image object from the pixel values
    plt.imshow(image_array)
    plt.show()
    print("Population:",random_images.loc[i, "population"])
    print(random_images.loc[i, "coordinates"])
    print("HDI:",random_images.loc[i, "hdi"])

sum(world_data.population)

X_train, X_test,y_train, y_test = train_test_split(world_data["pixel_values"],world_data["hdi"] ,
                                   random_state=104,
                                   test_size=0.20,
                                   shuffle=True)

X_trainpop , X_testpop = train_test_split(world_data["population"],
                                   random_state=104,
                                   test_size=0.20,
                                   shuffle=True)

X_train = np.array(X_train.to_list())
y_train = y_train.to_numpy()

X_test = np.array(X_test.to_list())
y_test = y_test.to_numpy()

X_trainpop = X_trainpop.to_numpy()
X_testpop = X_testpop.to_numpy()

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)
print(X_trainpop.shape)
print(X_testpop.shape)

X_trainpop.reshape(10799, 1)
X_testpop.reshape(2700, 1)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)
print(X_trainpop.shape)
print(X_testpop.shape)

for i in range(41, 50):

    image_array = X_train[i] # Get the pixel values of the image
    #image = Image.fromarray(image_array)  # Create a PIL Image object from the pixel values
    plt.imshow(image_array)
    plt.show()
    print(y_train[i])
    print(X_trainpop[i])

means = [world_data.population.mean()]
std_devs = [world_data.population.std()]

def stat_scaler(tensor):
  return     ( 2* ( (tensor - 5000) / ( 29000000 - 5000 )   )     - 1   )



from tensorflow.keras import layers
from tensorflow.keras.models import Model

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# Define the Picture (CNN) Stream

input_pic = layers.Input(shape=(200, 200, 3))
x         = layers.Lambda(preprocess_input)(input_pic)
x         = MobileNetV2(input_shape=((200, 200, 3)), include_top=False)(x)
x         = layers.GlobalAveragePooling2D()(x)
x         = layers.Dense(10, activation='relu')(x)
x         = Model(inputs=input_pic, outputs=x)


# Define the Stats (Feed-Forward) Stream

input_stats = layers.Input(shape=(1,))
y = layers.Lambda(stat_scaler)(input_stats)
y = layers.Dense(64, activation="relu")(y)
y = layers.Dense(10, activation="relu")(y)
y = Model(inputs=input_stats, outputs=y)


# Concatenate the two streams together
combined = layers.concatenate([x.output, y.output])

# Define joined Feed-Forward Layer
z = layers.Dense(4, activation="relu")(combined)

# Define output node of 1 linear neuron (regression task)
z = layers.Dense(1, activation="linear")(z)


# Define the final model
model = Model(inputs=[x.input, y.input], outputs=z)

from tensorflow.keras.optimizers import Adam

optimizer = Adam(learning_rate=0.001)

model.compile(loss='mse', optimizer="adam", metrics=['mean_absolute_error'])

model.fit(x=[X_train, X_trainpop], y=y_train, epochs=5)

model.save("testhdicnn.h5")

predictions = model.predict([X_test, X_testpop]).flatten()

plt.hist(predictions)

plt.hist(y_train)

model.evaluate([X_test, X_testpop] , y_test)

y_test.std()

for i in range(210, 220):
  plt.imshow(X_test[i])
  plt.show()
  print("Actual:",y_test[i])
  print("Predicted:",predictions[i])

